{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9520377,"sourceType":"datasetVersion","datasetId":5796380}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-01T03:15:10.683543Z","iopub.execute_input":"2024-10-01T03:15:10.683843Z","iopub.status.idle":"2024-10-01T03:15:11.643131Z","shell.execute_reply.started":"2024-10-01T03:15:10.683811Z","shell.execute_reply":"2024-10-01T03:15:11.642268Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cleanss/clean.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/cleanss/clean.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:15:32.307508Z","iopub.execute_input":"2024-10-01T03:15:32.308369Z","iopub.status.idle":"2024-10-01T03:15:33.769067Z","shell.execute_reply.started":"2024-10-01T03:15:32.308313Z","shell.execute_reply":"2024-10-01T03:15:33.768108Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:15:37.098886Z","iopub.execute_input":"2024-10-01T03:15:37.099878Z","iopub.status.idle":"2024-10-01T03:15:37.115688Z","shell.execute_reply.started":"2024-10-01T03:15:37.099821Z","shell.execute_reply":"2024-10-01T03:15:37.114684Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                             review  sentiment\n0           0  one reviewer mentioned watching oz episode you...          1\n1           1  wonderful little production filming technique ...          1\n2           2  thought wonderful way spend time hot summer we...          1\n3           3  basically there family little boy jake think t...          0\n4           4  petter matteis love time money visually stunni...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>one reviewer mentioned watching oz episode you...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>wonderful little production filming technique ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>basically there family little boy jake think t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>petter matteis love time money visually stunni...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(columns=['Unnamed: 0'], inplace= True)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:16:14.406742Z","iopub.execute_input":"2024-10-01T03:16:14.407159Z","iopub.status.idle":"2024-10-01T03:16:14.419046Z","shell.execute_reply.started":"2024-10-01T03:16:14.407117Z","shell.execute_reply":"2024-10-01T03:16:14.418002Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:16:20.887722Z","iopub.execute_input":"2024-10-01T03:16:20.888104Z","iopub.status.idle":"2024-10-01T03:16:20.897660Z","shell.execute_reply.started":"2024-10-01T03:16:20.888066Z","shell.execute_reply":"2024-10-01T03:16:20.896723Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment\n0  one reviewer mentioned watching oz episode you...          1\n1  wonderful little production filming technique ...          1\n2  thought wonderful way spend time hot summer we...          1\n3  basically there family little boy jake think t...          0\n4  petter matteis love time money visually stunni...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewer mentioned watching oz episode you...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production filming technique ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there family little boy jake think t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter matteis love time money visually stunni...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:16:28.093010Z","iopub.execute_input":"2024-10-01T03:16:28.093977Z","iopub.status.idle":"2024-10-01T03:16:28.099966Z","shell.execute_reply.started":"2024-10-01T03:16:28.093934Z","shell.execute_reply":"2024-10-01T03:16:28.098918Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(50000, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:16:38.961010Z","iopub.execute_input":"2024-10-01T03:16:38.961850Z","iopub.status.idle":"2024-10-01T03:16:39.070982Z","shell.execute_reply.started":"2024-10-01T03:16:38.961810Z","shell.execute_reply":"2024-10-01T03:16:39.070052Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"423"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:16:55.773542Z","iopub.execute_input":"2024-10-01T03:16:55.773913Z","iopub.status.idle":"2024-10-01T03:16:55.789775Z","shell.execute_reply.started":"2024-10-01T03:16:55.773877Z","shell.execute_reply":"2024-10-01T03:16:55.788848Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df=df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:18:10.951859Z","iopub.execute_input":"2024-10-01T03:18:10.952196Z","iopub.status.idle":"2024-10-01T03:18:11.056479Z","shell.execute_reply.started":"2024-10-01T03:18:10.952164Z","shell.execute_reply":"2024-10-01T03:18:11.055731Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:18:21.726519Z","iopub.execute_input":"2024-10-01T03:18:21.726892Z","iopub.status.idle":"2024-10-01T03:18:21.829489Z","shell.execute_reply.started":"2024-10-01T03:18:21.726856Z","shell.execute_reply":"2024-10-01T03:18:21.828545Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:19:33.555219Z","iopub.execute_input":"2024-10-01T03:19:33.556062Z","iopub.status.idle":"2024-10-01T03:19:33.566463Z","shell.execute_reply.started":"2024-10-01T03:19:33.556023Z","shell.execute_reply":"2024-10-01T03:19:33.565463Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"sentiment\n1    24882\n0    24695\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate word count for each review\ndf['word_count'] = df['review'].apply(lambda x: len(str(x).split()))\n\n# Calculate the average word count\navg_word_count = df['word_count'].mean()\n\n# Find the review with the maximum word count\nmax_word_count = df['word_count'].max()\nmax_review = df[df['word_count'] == max_word_count]['review'].values[0]\n\n# Display the results\nprint(f\"Average word count: {avg_word_count}\")\nprint(f\"Maximum word count: {max_word_count}\")\nprint(f\"Review with maximum word count: \\n{max_review}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:19:44.404383Z","iopub.execute_input":"2024-10-01T03:19:44.404768Z","iopub.status.idle":"2024-10-01T03:19:44.831304Z","shell.execute_reply.started":"2024-10-01T03:19:44.404730Z","shell.execute_reply":"2024-10-01T03:19:44.830443Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Average word count: 119.4285253242431\nMaximum word count: 1408\nReview with maximum word count: \nmatch tag team table match bubba ray spike dudley v eddie guerrero chris benoit bubba ray spike dudley started thing tag team table match eddie guerrero chris benoit according rule match opponent go table order get win benoit guerrero heated early taking turn hammering first spike bubba ray german suplex benoit bubba took wind dudley brother spike tried help brother referee restrained benoit guerrero ganged corner benoit stomping away bubba guerrero set table outside spike dashed ring somersaulted top rope onto guerrero outside recovering taking care spike guerrero slipped table ring helped wolverine set tandem set double superplex middle rope would put bubba table spike knocked table right brother came crashing guerrero benoit propped another table corner tried irish whip spike bubba dashed blocked brother bubba caught fire lifted opponent back body drop bubba slammed guerrero spike stomped wolverine top rope bubba held benoit bay spike soar wassup headbutt shortly benoit latched spike crossface match continued even spike tapped bubba came brother rescue managed sprawl benoit table bubba leapt middle rope benoit moved sent bubba crashing wood opponent didnt force table bubba allowed stay match first man eliminated shortly though spike put eddie table dudley dawg ring apron outside benoit put spike table moment later even score within second bubba nailed bubba bomb put benoit table gave dudleys win winner bubba ray spike dudleymatch cruiserweight championship jamie noble v billy kidman billy kidman challenged jamie noble brought nidia ring cruiserweight championship noble kidman locked tumbled ring raced back inside grappled kidman thwarted noble move noble fled outside ring nidia gave encouragement fight spread outside ring noble threw girlfriend challenger kidman tossed nidia aside taken modified arm bar noble continued attack kidmans injured arm back ring kidmans injured harm hampered offense continued battle hard noble tried put kidman away powerbomb challenger countered facebuster kidman went finish thing shooting star press noble broke attempt kidman went shooting star press time noble rolled harm way noble flipped kidman power bomb soon got pin retain wwe cruiserweight championship winner jamie noblematch european championship william regal v jeff hardy william regal took jeff hardy next attempt win back european championship jeff catapulted regal top rope took hurracanrana ring apron back ring jeff hit whisper wind knock regal loop jeff went swanton bomb regal got knee hit jeff devastating shot jeff managed surprise regal quick rollup though got pin keep european championship regal started bawling seeing hardy celebrate way back ramp winner jeff hardymatch chris jericho v john cena chris jericho promised end john cenas career match vengeance came next jericho tried teach cena lesson match began suplexing mat jericho continued knock cena around ring cockiness got better top rope jericho began showboat allowed cena grab superplex cena followed tiltawhirl slam taken nasty dropkick gut rookie recovered hit belly belly suplex couldnt put y2j away jericho launched lionsault cena dodged move jericho nailed bulldog connected lionsault go cover goaded cena foot could put wall jericho cena idea reversing move pin attempt getting 123 jericho went berserk match winner john cenamatch intercontinental championship rvd v brock lesnar via disqualification next big thing mr payperview tangled intercontinental championship line brock grabbed title ref draped shoulder momentarily glaring rvd van dam quickness gave brock fit early big man rolled ring kicked steel step frustration brock pulled together began take charge paul heyman beaming ringside brock slammed rvd hard floor outside ring brock began overpower rvd throwing ease top rope rvd landed painfully back suffer spine cracked steel ring step fight returned ring brock squeezing rvd around rib rvd broke away soon leveled brock kick temple rvd followed rolling thunder brock managed kick twocount fight looked like might soon rvd went fivestar frog splash brock though hoisted van dam onto shoulder went f5 rvd whirled brock ddt followed frog splash went pin heyman pulled ref ring ref immediately called disqualification soon traded blow heyman rvd leapt onto brock top rope threatened hit van terminator heyman grabbed rvds leg brock picked champ time connected f5 onto steel chair winner rvdmatch booker v big show booker faced big show oneonone next show withstood booker t kick punch slapped booker corner thrown ring booker picked chair ringside big show punched back booker face booker tried get back game choking show camera cable ringside booker smashed tv monitor spanish announcer position show skull delivered scissors kick put men table booker crawled back ring big show staggered moment later show grabbed booker throat met low blow kick face booker climbed top rope nailed somersaulting leg drop get pin winner booker tannouncement triple entered ring thunderous ovation fan hoped learn game would end competing could speak eric bishoff stopped game apologize getting involved personal business triple signed raw bischoff promised personal life would never come play bischoff said he spent past two year networking hollywood said everyone looking next breakout wwe superstar talking triple bischoff guaranteed triple signed raw hed getting top opportunity coming way stephanie mcmahon stepped issue pitch said personal history triple two know well said two unstoppable bischoff cut begged stop stephanie cited triple told bischoff said triple talent charisma bischoff said young time didnt know still lot experience stephanie two continued bicker back forth triple stepped microphone game said would easy say screw either one triple went shake bischoffs hand pulled away said would rather go devil know rather one doesnt know could go though shawn michael came shake thing hbk said last thing wanted cause trouble didnt want get involved remembered pledging bring triple nwo hbk said there nobody world triple better friend hbk told friend imagine two back together making bischoffs life living hell triple said tempting offer turned hugged hbk making official switch raw triple hbk left bischoff gloated victory bischoff said difference two he got testicle doesnt stephanie whacked bischoff side head leftmatch tag team championship match christian lance storm v hollywood hogan edge match started loud usa chant hogan shoving christian rope ring canadian took edge scored kick christian head planted facebuster storm get tag hogan hogan began hulk soon caught christian big boot leg drop storm broke count christian tossed hogan ring storm superkicked icon edge tagged soon dropped opponent speared corner turnbuckle missed spear strom hit ref hard instead edge nailed ddt ref could count test raced took hogan leveled edge boot storm tried get pin edge kicked two riksihi sprinted fend test allowing edge recover spear storm christian distracted ref though y2j dashed clocked edge tag team championship storm rolled got pinfall win title winner new tag team champion christian lance stormmatch wwe undisputed championship triple threat match rock v kurt angle undertaker three wwes successful superstar lined triple threat match undisputed championship hanging balance taker rock got face face kurt angle begging attention side got attention form beat form two men soon taker spilled ring rock brawled angle angle gave series suplexes took rock great one countered ddt managed twocount fight continued outside ring taker coming life clotheslining angle repeatedly smacking rock taker rock got back ring taker dropped rock sidewalk slam get twocount rock rebounded grabbed taker throat chokeslammed angle broke pin attempt likely would given rock title rock retaliated latching ankle lock kurt angle angle reversed move rock bottomed people champion soon rock disposed angle hit people elbow undertaker angle tried take advantage disabling great one outside ring covering taker kicked two count outside ring rock took big swig nearby water bottle spewed liquid taker face blind champion taker didnt stay disabled long managed overpower rock turn attention angle taker landed guillotine leg drop onto angle laying ring apron rock picked time break pin attempt kurt angle taker nailed rock ddt set chokeslam angle tried sneaking steel chair taker caught tomfoolery smacked hand referee got caught ensuing fire didnt see angle knock taker silly steel chair angle went cover taker rock lay prone dead man somehow got shoulder angle tried pin rock kicked rock got landed angle sharpshooter angle looked like tap taker kicked rock submission hold taker picked rock crashed last ride dead man covered win angle raced picked taker ankle lock taker went delirious pain managed counter picked angle last ride angle put triangle choke looked like taker pas rock broke angle hold find caught ankle lock rock got hold watched taker chokeslam angle rocky hit rock bottom taker refused go kicked angle whirled taker angle slam rock bottomed great one pinned winner new wwe champion rockfinally decent ppv lately ppv werent good one winner give ppv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.utils import resample\n\n# Assuming your dataframe has a 'review' column and a 'sentiment' column\n# Sentiment 1: Positive, Sentiment 0: Negative\n\n# Separate majority and minority classes\ndf_majority = df[df['sentiment'] == 1]\ndf_minority = df[df['sentiment'] == 0]\n\n# Resample to balance the classes\ndf_majority_downsampled = resample(df_majority, \n                                   replace=False,    # sample without replacement\n                                   n_samples=len(df_minority),  # match minority class\n                                   random_state=42)  # reproducibility\n\n# Combine minority class with downsampled majority class\ndf_balanced = pd.concat([df_majority_downsampled, df_minority])\n\n# Shuffle the data\ndf_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:22:29.097123Z","iopub.execute_input":"2024-10-01T03:22:29.097948Z","iopub.status.idle":"2024-10-01T03:22:29.810228Z","shell.execute_reply.started":"2024-10-01T03:22:29.097906Z","shell.execute_reply":"2024-10-01T03:22:29.809409Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import spacy\nimport time\n\n# Load SpaCy model\nnlp = spacy.load('en_core_web_sm')\n\n# Define the tokenizer function\ndef spacy_tokenizer(text):\n    doc = nlp(text)\n    return [token.text for token in doc if not token.is_stop and not token.is_punct]\n\n# Start the timer\nstart_time = time.time()\n\n# Apply the tokenizer to the 'review' column\ndf_balanced['tokens'] = df_balanced['review'].apply(spacy_tokenizer)\n\n# End the timer\nend_time = time.time()\n\n# Calculate the total time taken\ntime_taken = end_time - start_time\n\nprint(f\"Tokenization completed in {time_taken:.2f} seconds.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:30:30.511375Z","iopub.execute_input":"2024-10-01T03:30:30.511756Z","iopub.status.idle":"2024-10-01T03:47:19.195404Z","shell.execute_reply.started":"2024-10-01T03:30:30.511720Z","shell.execute_reply":"2024-10-01T03:47:19.194389Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Tokenization completed in 1007.72 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Example usage:\n# Tokenize the text\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(df_balanced['review'])\n\n# Convert text to sequences\nsequences = tokenizer.texts_to_sequences(df_balanced['review'])\n\n# Pad the sequences to ensure they are all of the same length\npadded_sequences = pad_sequences(sequences, maxlen=200)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T03:49:37.727138Z","iopub.execute_input":"2024-10-01T03:49:37.727820Z","iopub.status.idle":"2024-10-01T03:49:48.507279Z","shell.execute_reply.started":"2024-10-01T03:49:37.727777Z","shell.execute_reply":"2024-10-01T03:49:48.506244Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom sklearn.metrics import f1_score\nfrom keras.callbacks import Callback\n\n# Define the tokenizer and fit it on your text data\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(df_balanced['review'])\n\n# Convert text to sequences\nsequences = tokenizer.texts_to_sequences(df_balanced['review'])\n\n# Set the max_len (e.g., 200 or based on your data)\nmax_len = 200  # You can adjust this based on your data\n\n# Pad the sequences to ensure uniform length\npadded_sequences = pad_sequences(sequences, maxlen=max_len)\n\n# Prepare the input (X) and target (y) variables\nX = padded_sequences\ny = df_balanced['sentiment']  # Assuming the sentiment column is your target\n\n# Vocabulary size (+1 for padding index)\nvocab_size = len(tokenizer.word_index) + 1\n\n# Define the LSTM model\nmodel = Sequential()\n\n# Embedding layer: input_dim is vocab_size, output_dim is the dimensionality of embeddings\nmodel.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n\n# LSTM layer with Dropout\nmodel.add(LSTM(64))\nmodel.add(Dropout(0.5))  # 50% dropout\n\n# Dense layer for output (binary classification)\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Custom callback to compute F1 Score\nclass F1Score(Callback):\n    def __init__(self, validation_data):\n        super(F1Score, self).__init__()\n        self.validation_data = validation_data\n\n    def on_epoch_end(self, epoch, logs=None):\n        X_val, y_val = self.validation_data\n        y_pred = (self.model.predict(X_val) > 0.5).astype(\"int32\")\n        f1 = f1_score(y_val, y_pred)\n        print(f\" - f1_score: {f1:.4f}\")\n\n# Split the data into training and validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model with the F1Score callback\nmodel.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), callbacks=[F1Score(validation_data=(X_val, y_val))])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T04:06:59.636920Z","iopub.execute_input":"2024-10-01T04:06:59.637809Z","iopub.status.idle":"2024-10-01T04:08:35.518924Z","shell.execute_reply.started":"2024-10-01T04:06:59.637766Z","shell.execute_reply":"2024-10-01T04:08:35.518006Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n - f1_score: 0.8812\n\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.7842 - loss: 0.4436 - val_accuracy: 0.8840 - val_loss: 0.2840\nEpoch 2/5\n\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n - f1_score: 0.8818\n\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9040 - loss: 0.2455 - val_accuracy: 0.8803 - val_loss: 0.2851\nEpoch 3/5\n\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n - f1_score: 0.8756\n\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9245 - loss: 0.1978 - val_accuracy: 0.8789 - val_loss: 0.3094\nEpoch 4/5\n\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n - f1_score: 0.8782\n\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9391 - loss: 0.1614 - val_accuracy: 0.8797 - val_loss: 0.3323\nEpoch 5/5\n\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n - f1_score: 0.8793\n\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9481 - loss: 0.1379 - val_accuracy: 0.8791 - val_loss: 0.3526\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ce60ec6b130>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Your example reviews (5 positive and 5 negative)\nreviews = [\n    \"The movie was fantastic! I loved every moment of it.\",  # Positive\n    \"An amazing film with great storytelling and characters.\",  # Positive\n    \"What a delightful experience! Highly recommended.\",  # Positive\n    \"Incredible visuals and a wonderful plot. Must watch!\",  # Positive\n    \"This movie made me feel so good! Great performances.\",  # Positive\n    \"Worst movie ever. I regretted watching it.\",  # Negative\n    \"It was a complete waste of time. So boring.\",  # Negative\n    \"I did not enjoy this film at all. Very disappointing.\",  # Negative\n    \"The acting was terrible and the story was nonsensical.\",  # Negative\n    \"Absolutely not worth the hype. I hated it.\"  # Negative\n]\n\n# Tokenize and pad the reviews\nexample_sequences = tokenizer.texts_to_sequences(reviews)\npadded_examples = pad_sequences(example_sequences, maxlen=max_len)\n\n# Make predictions\npredictions = model.predict(padded_examples)\n\n# Display predictions, showing only the relevant probability\nfor i, review in enumerate(reviews):\n    prob_positive = predictions[i][0]  # Probability of the positive class\n    prob_negative = 1 - prob_positive  # Calculate probability of the negative class\n    sentiment = \"Positive\" if prob_positive > 0.5 else \"Negative\"\n    \n    if sentiment == \"Positive\":\n        print(f\"Review: {review}\\nPrediction: {sentiment} (Positive Probability: {prob_positive:.4f})\\n\")\n    else:\n        print(f\"Review: {review}\\nPrediction: {sentiment} (Negative Probability: {prob_negative:.4f})\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T04:19:22.084699Z","iopub.execute_input":"2024-10-01T04:19:22.085683Z","iopub.status.idle":"2024-10-01T04:19:22.167780Z","shell.execute_reply.started":"2024-10-01T04:19:22.085642Z","shell.execute_reply":"2024-10-01T04:19:22.166906Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\nReview: The movie was fantastic! I loved every moment of it.\nPrediction: Positive (Positive Probability: 0.8817)\n\nReview: An amazing film with great storytelling and characters.\nPrediction: Positive (Positive Probability: 0.8929)\n\nReview: What a delightful experience! Highly recommended.\nPrediction: Positive (Positive Probability: 0.9839)\n\nReview: Incredible visuals and a wonderful plot. Must watch!\nPrediction: Positive (Positive Probability: 0.8709)\n\nReview: This movie made me feel so good! Great performances.\nPrediction: Positive (Positive Probability: 0.7956)\n\nReview: Worst movie ever. I regretted watching it.\nPrediction: Negative (Negative Probability: 0.9595)\n\nReview: It was a complete waste of time. So boring.\nPrediction: Negative (Negative Probability: 0.9866)\n\nReview: I did not enjoy this film at all. Very disappointing.\nPrediction: Negative (Negative Probability: 0.8597)\n\nReview: The acting was terrible and the story was nonsensical.\nPrediction: Negative (Negative Probability: 0.9321)\n\nReview: Absolutely not worth the hype. I hated it.\nPrediction: Negative (Negative Probability: 0.8627)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}